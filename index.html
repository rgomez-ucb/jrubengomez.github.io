<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>J, Ruben Gomez | Computational Social Science</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      max-width: 900px;
      margin: 40px auto;
      padding: 0 20px;
      color: #111;
      line-height: 1.6;
    }
    h1, h2 {
      font-weight: 600;
      margin-top: 1.6em;
    }
    a {
      color: #005cc5;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    .project {
      margin-bottom: 28px;
    }
    .tools {
      color: #555;
      font-size: 0.95em;
    }
  </style>
</head>

<body>

<h1>Hi! I'm J. Ruben Gomez</h1>

<p>
About Me

I am a graduate researcher in computational social science studying how
misinformation, narrative dynamics, and algorithmic systems shape belief,
behavior, and collective outcomes in online communities.

My work sits at the intersection of statistical modeling, NLP, and
LLM-based analysis, with a focus on understanding *how* sociotechnical
systems influence sensemaking, trust, and vulnerability rather than
treating harmful behavior as a purely technical classification problem.
Across my research, I aim to uncover upstream mechanisms of persuasion,
alienation, and narrative reinforcement-and to identify opportunities for
designing technology that better serves human agency and dignity.

Prior to graduate study, I spent over seven years leading work researching 
Trust & Safety and Platform Integrity roles at Reddit and Twitter (X),
where I worked on misinformation detection, abusive content,
election integrity, and human-centered reporting systems at global scale.
This experience grounded my academic work in real-world constraints and
ethical tradeoffs, and continues to inform my approach to research as
something that must translate into practical, humane interventions.

At UC Berkeley, my current research includes panel-data modeling of online
influence and financial behavior, topic modeling and LLM analysis of
political discourse, and identity-conditioned experiments examining how
generative models respond to users experiencing alienation or grievance.
Across these projects, I am motivated by a central question: **how can we
design digital and physical systems that improve humankind 10, 20, and 30 
years into the future and beyond?**
</p>

<p>
<a href="https://github.com/jrubengomez">GitHub</a> ·
<a href="cv.pdf">CV (PDF)</a> ·
<a href="mailto:jrgomez1231@berkeley.edu">Contact</a>
</a>[LinkedIn](https://www.linkedin.com/in/jrubengomez)</a>
</p>

<h2>Selected Projects</h2>

<div class="project">
  <strong>Detecting Misinformation in Political Subreddits</strong>
  <p>
  Analyzed posts and comments from r/PoliticalDiscussion to identify latent
  misinformation narratives and engagement patterns using topic modeling
  and sentiment analysis.
  </p>
  <p class="tools">
  Python · BERTopic · VADER · pandas · VSCode · Git 
  </p>
  <a href="https://github.com/rgomez-ucb/misinfo_rddt.git">GitHub Repository</a>
</div>

<div class="project">
  <strong>Narrative Polarization and Market Behavior</strong>
  <p>
  An attempt to create a model that predicts online financial influencers a.k.a "Finfluencers" effects on retail tradining behaviors. 
  Panel regression analysis examining how sentiment shocks
  and influencer narratives predict trading volume in stock tradining.
  </p>
  <p class="tools">
  Python · PanelOLS · R
  </p>
  <a href="https://github.com/rgomez-ucb/finfluencers-retail-trading-stats.git">GitHub Repository</a>
</div>

<div class="project">
  <strong>LLM Archetypes and Online Radicalization</strong>
  <p>
  project explores how large language models respond to advice-seeking
  questions when conditioned on different identity archetypes that are
  theoretically susceptible to online radicalization and grievance-based
  online narratives.
  </p>
  <p class="tools">
  Python · APIs · HuggingFace · Pandas · LLMs
  </p>
  <a href="https://github.com/rubengomez/REPO_NAME">GitHub Repository</a>
</div>

<h2>Research Interests</h2>
<ul>
  <li>Computational social science</li>
  <li>Misinformation and narrative dynamics</li>
  <li>LLMs, identity, and vulnerability</li>
  <li>Creating tech that advances humankind not hurts it</li>
</ul>

<h2>## Research in the News</h2>

My research and applied work on platform integrity, misinformation, and
human-centered safety systems has informed product launches and public
discussion, including:

- [Twitter Launches Beta Test of Anti-Abuse Tool “Safety Mode”](https://techcrunch.com/2022/02/15/twitter-expands-access-to-anti-abuse-tool-safety-mode-adds-prompts-to-enable-it/)*
- [Twitter Rolls Out Redesigned Misinformation Warning Labels](https://apnews.com/article/technology-business-media-social-media-misinformation-ae496a53fbc761146627fa534cb2f8d9)
- [Twitter Says Labels and Warnings Slowed Spread of False Election Claims](https://www.wsj.com/tech/twitter-says-labels-and-warnings-slowed-spread-of-false-election-claims-11605214925)
- [Twitter’s New Reporting Process Centers on Human-First Design](https://blog.x.com/common-thread/en/topics/stories/2021/twitters-new-reporting-process-centers-on-a-human-first-design)

</body>
</html>
